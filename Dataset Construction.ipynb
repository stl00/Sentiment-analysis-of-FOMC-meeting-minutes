{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b4eaa2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T03:09:46.213673Z",
     "start_time": "2023-04-30T03:09:46.195102Z"
    }
   },
   "outputs": [],
   "source": [
    "Hawkish = [\n",
    "    \"business\", \"businesses\", \"demand\", \"economy\", \"employment\", \"energy\",\n",
    "    \"equity\", \"expansion\", \"financial\", \"housing\", \"income\", \"indicators\",\n",
    "    \"inflationary\", \"investment\", \"investments\", \"manufacturing\", \"outlook\",\n",
    "    \"inflation\", \"prices\", \"outhut\", \"labor\", \"securities\", \"slack\",\n",
    "    \"recovery\", \"toll\", \"wage\", \"resource\"\n",
    "]\n",
    "\n",
    "Dovish = [\n",
    "    \"accommodation\", \"devastation\", \"downturn\", \"recession\", \"unemployment\"\n",
    "]\n",
    "\n",
    "Positive = [\n",
    "    \"abating\", \"accelerated\", \"add\", \"advance\", \"advanced\", \"augmented\",\n",
    "    \"balanced\", \"better\", \"bolsters\", \"boom\", \"booming\", \"boost\", \"boosted\",\n",
    "    \"eased\", \"elevated\", \"elevating\", \"expand\", \"expanding\", \"expansionary\",\n",
    "    \"extend\", \"extended\", \"fast\", \"faster\", \"firmer\", \"gains\", \"growing\",\n",
    "    \"heightened\", \"high\", \"higher\", \"improved\", \"improvement\", \"improving\",\n",
    "    \"increase\", \"increased\", \"increases\", \"increasing\", \"more\", \"raise\",\n",
    "    \"rapid\", \"rebounded\", \"recovering\", \"rise\", \"risen\", \"rising\", \"robust\",\n",
    "    \"rose\", \"significant\", \"solid\", \"sooner\", \"spike\", \"spikes\", \"spiking\",\n",
    "    \"stable\", \"strength\", \"strengthen\", \"strengthened\", \"strengthens\",\n",
    "    \"strong\", \"stronger\", \"supportive\", \"up\", \"upside\", \"upswing\", \"uptick\"\n",
    "]\n",
    "\n",
    "Negative = [\n",
    "    \"adverse\", \"back\", \"below\", \"constrained\", \"contract\", \"contracting\",\n",
    "    \"contraction\", \"cooling\", \"correction\", \"dampen\", \"damping\", \"decelerated\",\n",
    "    \"decline\", \"declined\", \"declines\", \"declining\", \"decrease\", \"decreases\",\n",
    "    \"decreasing\", \"deepening\", \"depressed\", \"deteriorated\", \"deterioration\",\n",
    "    \"diminished\", \"disappointing\", \"dislocation\", \"disruptions\", \"down\",\n",
    "    \"downbeat\", \"downside\", \"drop\", \"dropping\", \"ebbed\", \"erosion\", \"fade\",\n",
    "    \"faded\", \"fading\", \"fall\", \"fallen\", \"falling\", \"fell\", \"insufficient\",\n",
    "    \"less\", \"limit\", \"low\", \"lower\", \"moderated\", \"moderating\", \"moderation\",\n",
    "    \"reduce\", \"reduced\", \"reduction\", \"reluctant\", \"removed\", \"restrain\",\n",
    "    \"restrained\", \"restraining\", \"restraint\", \"resumption\", \"reversed\",\n",
    "    \"slack\", \"slow\", \"slowed\", \"slower\", \"slowing\", \"slowly\", \"sluggish\",\n",
    "    \"sluggishness\", \"slumped\", \"soft\", \"softened\", \"softening\", \"stimulate\",\n",
    "    \"strained\", \"strains\", \"stress\", \"subdued\", \"tragic\", \"turmoil\",\n",
    "    \"underutilization\", \"volatile\", \"vulnerable\", \"wary\", \"weak\", \"weakened\",\n",
    "    \"weaker\", \"weakness\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a054f83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T03:10:00.197592Z",
     "start_time": "2023-04-30T03:09:52.634162Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize and clean text\n",
    "def clean_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{string.punctuation}]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "        \n",
    "    # Convert to lowercase and remove non-alphabetic characters\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return clean_words\n",
    "\n",
    "# Calculate sentiment score for a sentence\n",
    "def sentiment_score(sentence, Hawkish, Dovish, Positive, Negative):\n",
    "    tokens = clean_and_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "    hawkish_count = sum([1 for token in tokens if token in Hawkish])\n",
    "    dovish_count = sum([1 for token in tokens if token in Dovish])\n",
    "    positive_count = sum([1 for token in tokens if token in Positive])\n",
    "    negative_count = sum([1 for token in tokens if token in Negative])\n",
    "    \n",
    "    if hawkish_count > dovish_count:\n",
    "        if positive_count > negative_count:\n",
    "            return 1\n",
    "        elif positive_count < negative_count:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    elif dovish_count > hawkish_count:\n",
    "        if positive_count > negative_count:\n",
    "            return -1\n",
    "        elif positive_count < negative_count:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Calculate average sentiment score for a document\n",
    "def document_sentiment(document, Hawkish, Dovish, Positive, Negative):\n",
    "    sentences = document.split('.')\n",
    "    scores = [sentiment_score(sentence, Hawkish, Dovish, Positive, Negative) for sentence in sentences]\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Calculate sentiment scores and add them as a new column to the dataframe\n",
    "df['sentiment_score'] = df['text'].apply(lambda x: document_sentiment(x, Hawkish, Dovish, Positive, Negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9a4e9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:00:23.100943Z",
     "start_time": "2023-04-26T20:00:16.122586Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_training_data = []\n",
    "\n",
    "for ts in df['text']:   \n",
    "    sentences = ts.split('.')\n",
    "    for sentence in sentences:\n",
    "        sentiment_training_data.append({\n",
    "            'text': sentence,\n",
    "            'label': sentiment_score(sentence, Hawkish, Dovish, Positive, Negative)\n",
    "        })\n",
    "        \n",
    "sentiment_training_data = pd.DataFrame(sentiment_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b57afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T20:32:26.149048Z",
     "start_time": "2023-04-29T20:32:25.215445Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fed_Scrape-2015-2023.csv')\n",
    "df = df[[\"Type\",\"Text\"]]\n",
    "df = df[df[\"Type\"] == 0]\n",
    "\n",
    "stmts_data = []\n",
    "\n",
    "for ts in df['Text']:   \n",
    "    sentences = ts.split('.')\n",
    "    for sentence in sentences:\n",
    "        stmts_data.append({\n",
    "            'text': sentence,\n",
    "            'label': sentiment_score(sentence, Hawkish, Dovish, Positive, Negative)\n",
    "        })\n",
    "        \n",
    "stmts_data = pd.DataFrame(stmts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2867c27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T01:23:35.330285Z",
     "start_time": "2023-04-30T01:23:28.918529Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fed_Scrape-2015-2023.csv')\n",
    "df = df[[\"Type\",\"Text\"]]\n",
    "df = df[df[\"Type\"] == 1]\n",
    "\n",
    "mn_data = []\n",
    "\n",
    "for ts in df['Text']:   \n",
    "    sentences = ts.split('.')\n",
    "    for sentence in sentences:\n",
    "        mn_data.append({\n",
    "            'text': sentence,\n",
    "            'label': sentiment_score(sentence, Hawkish, Dovish, Positive, Negative)\n",
    "        })\n",
    "        \n",
    "mn_data = pd.DataFrame(mn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf730c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T20:33:49.363696Z",
     "start_time": "2023-04-29T20:33:49.347486Z"
    }
   },
   "outputs": [],
   "source": [
    "stmts_data[stmts_data[\"label\"] != 0].to_csv('stmts_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e817c56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T01:23:38.067463Z",
     "start_time": "2023-04-30T01:23:38.008813Z"
    }
   },
   "outputs": [],
   "source": [
    "mn_data[mn_data[\"label\"] != 0].to_csv('mn_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25640fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:03:30.013496Z",
     "start_time": "2023-04-26T20:03:29.939257Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_training_data[sentiment_training_data['label'] != 0].to_csv('sentiment_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
